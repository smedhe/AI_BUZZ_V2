<wiki_structure>
  <title>vLLM Wiki</title>
  <description>vLLM project documentation</description>
  <sections>
    <section id="section-1">
      <title>Overview</title>
      <pages>
        <page_ref>page-1</page_ref>
        <page_ref>page-28</page_ref>
        <page_ref>page-45</page_ref>
        <page_ref>page-51</page_ref>
      </pages>
    </section>
    <section id="section-2">
      <title>Core Features</title>
      <pages>
        <page_ref>page-2</page_ref>
        <page_ref>page-11</page_ref>
        <page_ref>page-29</page_ref>
        <page_ref>page-52</page_ref>
      </pages>
    </section>
    <section id="section-3">
      <title>Deployment/Infrastructure</title>
      <pages>
        <page_ref>page-3</page_ref>
        <page_ref>page-14</page_ref>
        <page_ref>page-30</page_ref>
        <page_ref>page-48</page_ref>
      </pages>
    </section>
    <section id="section-4">
      <title>Examples and Notebooks</title>
      <pages>
        <page_ref>page-4</page_ref>
        <page_ref>page-21</page_ref>
        <page_ref>page-25</page_ref>
        <page_ref>page-49</page_ref>
      </pages>
    </section>
    <section id="section-5">
      <title>Model Integration</title>
      <pages>
        <page_ref>page-7</page_ref>
        <page_ref>page-20</page_ref>
        <page_ref>page-42</page_ref>
      </pages>
    </section>
    <section id="section-6">
      <title>System Architecture</title>
      <pages>
        <page_ref>page-13</page_ref>
        <page_ref>page-50</page_ref>
      </pages>
    </section>
  </sections>
  <pages>
    <page id="page-1">
      <title>Introduction to vLLM</title>
      <description>vLLM project overview</description>
      <importance>high</importance>
      <relevant_files>
        <file_path>README.md</file_path>
        <file_path>RELEASE.md</file_path>
        <file_path>SECURITY.md</file_path>
      </relevant_files>
      <related_pages>
        <related>page-28</related>
      </related_pages>
      <parent_section>section-1</parent_section>
    </page>
    <page id="page-2">
      <title>Setup and Installation</title>
      <description>vLLM setup and installation process</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>MANIFEST.in</file_path>
        <file_path>pyproject.toml</file_path>
        <file_path>setup.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-11</related>
      </related_pages>
      <parent_section>section-2</parent_section>
    </page>
    <page id="page-3">
      <title>Docker and Containerization</title>
      <description>vLLM Docker and containerization process</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>.dockerignore</file_path>
        <file_path>.gitignore</file_path>
        <file_path>format.sh</file_path>
      </relevant_files>
      <related_pages>
        <related>page-14</related>
      </related_pages>
      <parent_section>section-3</parent_section>
    </page>
    <page id="page-4">
      <title>Using vLLM with Existing Torch</title>
      <description>vLLM usage with existing Torch</description>
      <importance>low</importance>
      <relevant_files>
        <file_path>README.md</file_path>
        <file_path>mkdocs.yaml</file_path>
        <file_path>use_existing_torch.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-21</related>
      </related_pages>
      <parent_section>section-4</parent_section>
    </page>
    <page id="page-7">
      <title>Model Integration Tests</title>
      <description>vLLM model integration tests</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>tests/kernels/moe/test_deepep_moe.py</file_path>
        <file_path>tests/kernels/moe/test_moe.py</file_path>
        <file_path>tests/models/multimodal/generation/vlm_utils/model_utils.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-20</related>
      </related_pages>
      <parent_section>section-5</parent_section>
    </page>
    <page id="page-13">
      <title>High-Level Architecture</title>
      <description>vLLM system architecture</description>
      <importance>high</importance>
      <relevant_files>
        <file_path>csrc/core/scalar_type.hpp</file_path>
        <file_path>csrc/cutlass_extensions/common.hpp</file_path>
        <file_path>csrc/cutlass_extensions/vllm_cutlass_library_extension.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-50</related>
      </related_pages>
      <parent_section>section-6</parent_section>
    </page>
    <page id="page-14">
      <title>Deployment Options</title>
      <description>vLLM deployment options</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>csrc/cpu/dnnl_helper.h</file_path>
        <file_path>csrc/cpu/sgl-kernels/moe.cpp</file_path>
        <file_path>csrc/rocm/torch_bindings.cpp</file_path>
      </relevant_files>
      <related_pages>
        <related>page-30</related>
      </related_pages>
      <parent_section>section-3</parent_section>
    </page>
    <page id="page-20">
      <title>Model Registry</title>
      <description>vLLM model registry</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>vllm/model_executor/layers/quantization/modelopt.py</file_path>
        <file_path>vllm/model_executor/models/registry.py</file_path>
        <file_path>vllm/model_executor/models/utils.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-7</related>
      </related_pages>
      <parent_section>section-5</parent_section>
    </page>
    <page id="page-21">
      <title>Example Usage</title>
      <description>vLLM example usage</description>
      <importance>low</importance>
      <relevant_files>
        <file_path>vllm/benchmarks/datasets.py</file_path>
        <file_path>vllm/benchmarks/serve.py</file_path>
        <file_path>vllm/entrypoints/openai/run_batch.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-4</related>
      </related_pages>
      <parent_section>section-4</parent_section>
    </page>
    <page id="page-25">
      <title>Offline Inference Examples</title>
      <description>vLLM offline inference examples</description>
      <importance>high</importance>
      <relevant_files>
        <file_path>examples/offline_inference/audio_language.py</file_path>
        <file_path>examples/offline_inference/vision_language.py</file_path>
        <file_path>examples/offline_inference/vision_language_pooling.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-26</related>
      </related_pages>
      <parent_section>section-4</parent_section>
    </page>
    <page id="page-28">
      <title>vLLM Project Overview</title>
      <description>vLLM project overview</description>
      <importance>high</importance>
      <relevant_files>
        <file_path>examples/others/lmcache/README.md</file_path>
        <file_path>examples/others/logging_configuration.md</file_path>
      </relevant_files>
      <related_pages>
        <related>page-1</related>
      </related_pages>
      <parent_section>section-1</parent_section>
    </page>
    <page id="page-29">
      <title>vLLM Core Features</title>
      <description>vLLM core features</description>
      <importance>high</importance>
      <relevant_files>
        <file_path>examples/offline_inference/lora_with_quantization_inference.py</file_path>
        <file_path>examples/offline_inference/rlhf_utils.py</file_path>
      </relevant_files>
      <related_pages>
        <related>page-2</related>
      </related_pages>
      <parent_section>section-2</parent_section>
    </page>
    <page id="page-30">
      <title>vLLM Deployment and Infrastructure</title>
      <description>vLLM deployment and infrastructure</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>examples/online_serving/chart-helm/templates/deployment.yaml</file_path>
        <file_path>examples/online_serving/chart-helm/templates/service.yaml</file_path>
      </relevant_files>
      <related_pages>
        <related>page-14</related>
      </related_pages>
      <parent_section>section-3</parent_section>
    </page>
    <page id="page-45">
      <title>Introduction to vLLM</title>
      <description>vLLM introduction</description>
      <importance>high</importance>
      <relevant_files>
        <file_path>docs/README.md</file_path>
        <file_path>docs/getting_started/quickstart.md</file_path>
        <file_path>docs/usage/README.md</file_path>
      </relevant_files>
      <related_pages>
        <related>page-1</related>
      </related_pages>
      <parent_section>section-1</parent_section>
    </page>
    <page id="page-50">
      <title>Architecture Overview</title>
      <description>vLLM architecture overview</description>
      <importance>medium</importance>
      <relevant_files>
        <file_path>docs/design/arch_overview.md</file_path>
        <file_path>docs/design/prefix_caching.md</file_path>
      </relevant_files>
      <related_pages>
        <related>page-13</related>
      </related_pages>
      <parent_section>section-6</parent_section>
    </page>
  </pages>
</wiki_structure>