{"meta":{"source_url":"https://github.com/quic/efficient-transformers/tree/main","owner":"quic","repo":"efficient-transformers","branch":"main","subpath":"","created_at":"2025-09-11T07:35:47Z","graph_id":"e472daf5ae36","totals":{"files":255,"classes":277,"functions":385,"imports":1146},"schema":"v2-compact"},"dicts":{"imports":["QEfficient.utils.constants","QEfficient.utils.logging_utils","QEfficient.utils.test_utils","json","os","pytest","shutil","transformers","QEfficient.utils.hash_utils","random","QEfficient.peft.onnx_transforms","onnx","textwrap","QEfficient","numpy","peft","time","torch","QEfficient.peft.lora","QEfficient.utils","pathlib","QEfficient.generation.text_generation_inference","QEfficient.transformers.models.modeling_auto","QEfficient.utils._utils","QEfficient.utils.device_utils","vllm","QEfficient.customop.matmulnbits","QEfficient.transformers.models.pytorch_transforms","QEfficient.transformers.quantizers.awq","QEfficient.transformers.quantizers.gptq","QEfficient.transformers.quantizers.quant_transforms","QEfficient.transformers.spd.turbo","platform","transformers.cache_utils","copy","QEfficient.generation.cloud_infer","typing","dataclasses","QEfficient.transformers.embeddings.embedding_utils","onnxruntime","QEfficient.exporter.export_hf_to_cloud_ai_100","QEfficient.transformers.quantizers.auto","QEfficient.utils.run_utils","PIL","io","requests","datasets","importlib","QEfficient.cloud.finetune","QEfficient.finetune.utils.helper","tests.finetune","torch.optim","torch.utils.data","QEfficient.base.pytorch_transforms","QEfficient.base.onnx_transforms","QEfficient.base.modeling_qeff","types","QEfficient.cloud.infer","QEfficient.cloud.execute","QEfficient.cloud.export","yaml","QEfficient.base","QEfficient.compile.compile_helper","QEfficient.peft","QEfficient.transformers.transform","QEfficient.utils.model_registery","qaicrt","sys","warnings","safetensors.torch","logging","QEfficient.utils.generate_inputs","QEfficient.transformers.modeling_utils","huggingface_hub","QEfficient.transformers.models.llama_swiftkv.modeling_llama_swiftkv","math","re","subprocess","torch.nn","torchvision.transforms","torchvision.transforms.functional","hashlib","QEfficient.utils.cache","inspect","requests.exceptions","xml.etree.ElementTree","QEfficient.peft.peft_model","QEfficient.peft.pytorch_transforms","transformers.generation.streamers","QEfficient.peft.auto","QEfficient.peft.lora.layers","QEfficient.peft.lora.lora_model","QEfficient.transformers.models.llama.modeling_llama","QEfficient.transformers.models.mistral.modeling_mistral","QEfficient.peft.lora.pytorch_transforms","QEfficient.peft.lora.auto","transformers.modeling_outputs","QEfficient.customop","torch.nn.functional","onnxscript","QEfficient.customop.ctx_scatter_gather","QEfficient.customop.ctx_scatter_gather_cb","QEfficient.customop.rms_norm","collections","QAicApi_pb2","QEfficient.utils.spd_utils","QEfficient.transformers.cache_utils","models.codegen.modeling_codegen","models.falcon.modeling_falcon","models.gemma.modeling_gemma","models.gemma2.modeling_gemma2","models.gpt2.modeling_gpt2","models.gpt_bigcode.modeling_gpt_bigcode","models.gptj.modeling_gptj","models.llama.modeling_llama","models.mistral.modeling_mistral","models.mixtral_moe.modeling_mixtral","models.mpt.modeling_mpt","models.phi.modeling_phi","models.phi3.modeling_phi3","models.qwen2.modeling_qwen2","models.starcoder2.modeling_starcoder2","models.whisper.modeling_whisper","transformers.models.auto.modeling_auto","transformers.models.codegen.modeling_codegen","transformers.models.falcon.modeling_falcon","transformers.models.gemma.modeling_gemma","transformers.models.gemma2.modeling_gemma2","transformers.models.gpt2.modeling_gpt2","transformers.models.gpt_bigcode.modeling_gpt_bigcode","transformers.models.gptj.modeling_gptj","transformers.models.llama.modeling_llama","transformers.models.mistral.modeling_mistral","transformers.models.mixtral.modeling_mixtral","transformers.models.mllama.modeling_mllama","transformers.models.mpt.modeling_mpt","transformers.models.phi.modeling_phi","transformers.models.phi3.modeling_phi3","transformers.models.qwen2.modeling_qwen2","transformers.models.starcoder2.modeling_starcoder2","transformers.models.whisper.modeling_whisper","QEfficient.utils.checkpoint_utils","QEfficient.transformers.quantizers.quantizer_compressed_tensors","QEfficient.transformers.quantizers.quantizer_utils","QEfficient.transformers.quantizers.quantizer_awq","QEfficient.transformers.quantizers.quantizer_gptq","transformers.quantizers.auto","transformers.quantizers.quantizer_awq","transformers.quantizers.quantizer_compressed_tensors","transformers.quantizers.quantizer_gptq","transformers.utils.quantization_config","transformers.integrations.awq","enum","transformers.quantizers","QEfficient.transformers.models.codegen.modeling_codegen","QEfficient.transformers.models.falcon.modeling_falcon","QEfficient.transformers.models.gemma.modeling_gemma","QEfficient.transformers.models.gemma2.modeling_gemma2","QEfficient.transformers.models.gemma3.modeling_gemma3","QEfficient.transformers.models.gpt2.modeling_gpt2","QEfficient.transformers.models.gpt_bigcode.modeling_gpt_bigcode","QEfficient.transformers.models.gptj.modeling_gptj","QEfficient.transformers.models.granite.modeling_granite","QEfficient.transformers.models.granitemoe.modeling_granitemoe","QEfficient.transformers.models.grok_1.modeling_grok1","QEfficient.transformers.models.internvl.modeling_internvl","QEfficient.transformers.models.llama4.modeling_llama4","QEfficient.transformers.models.llava.modeling_llava","QEfficient.transformers.models.llava_next.modeling_llava_next","QEfficient.transformers.models.mixtral_moe.modeling_mixtral","QEfficient.transformers.models.mllama.modeling_mllama","QEfficient.transformers.models.mpt.modeling_mpt","QEfficient.transformers.models.phi.modeling_phi","QEfficient.transformers.models.phi3.modeling_phi3","QEfficient.transformers.models.qwen2.modeling_qwen2","QEfficient.transformers.models.starcoder2.modeling_starcoder2","QEfficient.transformers.models.whisper.modeling_whisper","QEfficient.transformers.post_processing","QEfficient.transformers.sampler.sampler","QEfficient.transformers.spd.spd_transform_forward","transformers.models.gemma3.modeling_gemma3","transformers.models.granite.modeling_granite","transformers.models.granitemoe.modeling_granitemoe","transformers.models.llama4.modeling_llama4","transformers.models.llava.modeling_llava","transformers.models.llava_next.modeling_llava_next","QEfficient.transformers.modeling_attn_mask_utils","torch.utils.checkpoint","transformers.modeling_attn_mask_utils","transformers.modeling_utils","transformers.generation","transformers.utils.import_utils","transformers.modeling_rope_utils","QEfficient.utils.generate_qnn_network_specialization_config","QEfficient.compile.qnn_compiler","QEfficient.finetune.configs.training","QEfficient.finetune.utils.logging_utils","fire","torch_qaic","utils.config_utils","utils.dataset_utils","utils.train_utils","itertools","contextlib","torch.amp","torch.qaic.amp","torch_qaic.debug","torch_qaic.profile","datetime","QEfficient.finetune.data.sampler","QEfficient.finetune.dataset.dataset_config","torch.distributed","transformers.data","argparse","matplotlib.pyplot","functools","torch.utils.tensorboard","torchmetrics","tqdm","QEfficient.finetune.configs.dataset_config","QEfficient.finetune.configs.peft_config","QEfficient.finetune.dataset.alpaca_dataset","QEfficient.finetune.dataset.custom_dataset","QEfficient.finetune.dataset.grammar_dataset","QEfficient.finetune.dataset.gsm8k_dataset","QEfficient.finetune.dataset.imdb_dataset","QEfficient.base.common","QEfficient.exporter.export_utils","abc","gc","QEfficient.finetune.utils.config_utils","QEfficient.finetune.utils.dataset_utils","QEfficient.finetune.utils.device_map","QEfficient.finetune.utils.parser","QEfficient.finetune.utils.train_utils","torch.optim.lr_scheduler","InferenceSetIOBuffer"]},"files":[{"path":"Dockerfile","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"CONTRIBUTING.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"CODE-OF-CONDUCT.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":".gitignore","lang":"text","classes":[],"functions":[],"imports":[]},{"path":".pre-commit-config.yaml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"pyproject.toml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"MANIFEST.in","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"LICENSE","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"tests/README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"tests/conftest.py","lang":"python","classes":[],"functions":["custom_causal_model_config_dict","get_custom_model_config_dict","pytest_sessionfinish","pytest_sessionstart","qeff_models_clean_up"],"imports":[0,1,2,3,4,5,6,7]},{"path":"tests/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"tests/utils/test_hash_utils.py","lang":"python","classes":[],"functions":["get_random_string","test_hash_dict_params","test_json_serializable","test_to_hashable","test_to_hashable_dict","test_to_hashable_float_nan","test_to_hashable_set"],"imports":[0,8,3,5,9]},{"path":"tests/peft/test_peft_onnx_transforms.py","lang":"python","classes":[],"functions":["test_adapter_weights_to_inputs_transform"],"imports":[10,11,12]},{"path":"tests/peft/test_peft_model.py","lang":"python","classes":[],"functions":["create_peft_model","test_auto_peft_model_for_causal_lm_activate_invalid","test_auto_peft_model_for_causal_lm_compile_generate","test_auto_peft_model_for_causal_lm_export","test_auto_peft_model_for_causal_lm_from_pretrained","test_auto_peft_model_for_causal_lm_hash","test_auto_peft_model_for_causal_lm_init"],"imports":[13,14,11,4,15,5,16,17,7]},{"path":"tests/peft/lora/test_lora_model.py","lang":"python","classes":[],"functions":["create_lora_base_model","test_auto_lora_model_for_causal_lm_cb_compile_generate","test_auto_lora_model_for_causal_lm_from_pretrained","test_auto_lora_model_for_causal_lm_hash","test_auto_lora_model_for_causal_lm_init","test_auto_lora_model_for_causal_lm_init_from_unsupported_model","test_auto_lora_model_for_causal_lm_load_unload_adapter","test_auto_lora_model_for_causal_lm_noncb_export_compile_generate","test_auto_peft_model_for_causal_lm_from_pretrained"],"imports":[13,18,19,14,4,20,15,5,16,7]},{"path":"tests/text_generation/test_text_generation.py","lang":"python","classes":[],"functions":["load_causal_lm_model","test_generate_text_stream"],"imports":[21,22,19,23,0,24,4,5,7]},{"path":"tests/vllm/test_qaic_output_consistency.py","lang":"python","classes":[],"functions":["test_output_consistency"],"imports":[5,9,25]},{"path":"tests/transformers/test_transformer_pytorch_transforms.py","lang":"python","classes":[],"functions":["compare_original_vs_kv_model_pt_outputs","create_qaic_model_inputs","run_kv_cache_transform_and_test","test_awq_to_matmulnbits_transform","test_gptq_to_matmulnbits_transform","test_kv_cache_transform","test_rms_norm_ops_transform","test_spd_proj_transform","test_spd_transform"],"imports":[26,22,27,28,29,30,31,23,1,32,5,17,7,33]},{"path":"tests/transformers/test_speech_seq2seq.py","lang":"python","classes":[],"functions":["test_causal_lm_compile","test_seq2seq_export_and_hash","test_seq2seq_hash_creation","test_seq2seq_init","test_seq2seq_pretrained","test_seq2seq_unsupported","tmp_cache"],"imports":[22,8,34,11,4,5,16,7]},{"path":"tests/transformers/test_causal_lm.py","lang":"python","classes":[],"functions":["test_causal_lm_compile","test_causal_lm_export_and_hash","test_causal_lm_hash_creation","test_causal_lm_init","test_causal_lm_pretrained","test_causal_lm_unsupported","tmp_cache"],"imports":[22,19,8,34,11,4,5,16,7]},{"path":"tests/transformers/spd/test_spd_inference.py","lang":"python","classes":[],"functions":["get_padded_input_len","run_prefill_on_draft_and_target","split_dlm_bonus_token_inputs","test_spec_decode_inference"],"imports":[13,35,0,24,14,4,5,16,7,36]},{"path":"tests/transformers/spd/test_pld_inference.py","lang":"python","classes":["CloudAI100ExecInfo","PerfMetrics"],"functions":["find_candidate_pred_tokens","get_padded_input_len","run_prefill_on_draft_and_target","test_pld_spec_decode_inference"],"imports":[13,35,0,24,37,14,5,16,7,36]},{"path":"tests/transformers/models/test_embedding_models.py","lang":"python","classes":[],"functions":["check_embed_pytorch_vs_ort_vs_ai100","test_embed_model_pytorch_vs_onnx_vs_ai100","test_embed_model_pytorch_vs_onnx_vs_ai100_multiple_seq_len","test_embed_model_pytorch_vs_onnx_vs_ai100_multiple_seq_len_qnn","test_embed_model_pytorch_vs_onnx_vs_ai100_pooling","test_embed_model_pytorch_vs_onnx_vs_ai100_pooling_qnn","test_embed_model_pytorch_vs_onnx_vs_ai100_qnn"],"imports":[38,22,23,0,14,39,4,5,17,7,36]},{"path":"tests/transformers/models/custom_tiny_model_configs.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"tests/transformers/models/test_causal_lm_models.py","lang":"python","classes":[],"functions":["check_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100","get_custom_n_layers","load_causal_lm_model","test_causal_lm_export_with_deprecated_api","test_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100","test_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100_pl1","test_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100_pl1_qnn","test_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100_qnn","test_causal_tlm_pytorch_vs_kv_vs_ort_vs_ai100","test_custom_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100","test_custom_causal_lm_pytorch_vs_kv_vs_ort_vs_ai100_qnn","test_custom_causal_tlm_pytorch_vs_kv_vs_ort_vs_ai100","test_prefiill_only_pytorch_vs_kv_vs_ort_vs_ai100","test_prefiill_only_pytorch_vs_kv_vs_ort_vs_ai100_qnn"],"imports":[40,22,41,19,23,0,24,42,2,34,14,4,5,17,7,36]},{"path":"tests/transformers/models/test_image_text_to_text_models.py","lang":"python","classes":[],"functions":["check_image_text_to_text_pytorch_vs_kv_vs_ort_vs_ai100","check_intern_image_text_to_text_pytorch_vs_kv_vs_ort_vs_ai100","load_image_text_to_text_model","set_num_layers","test_image_text_to_text_intern_pytorch_vs_kv_vs_ort_vs_ai100","test_image_text_to_text_intern_pytorch_vs_kv_vs_ort_vs_ai100_qnn","test_image_text_to_text_pytorch_vs_kv_vs_ort_vs_ai100","test_image_text_to_text_pytorch_vs_kv_vs_ort_vs_ai100_qnn"],"imports":[43,22,19,23,0,24,42,2,44,4,5,45,17,7,36]},{"path":"tests/transformers/models/test_prefix_caching.py","lang":"python","classes":[],"functions":["prefix_caching_inference","test_simple_prefix_caching","test_simple_prefix_caching_qnn"],"imports":[21,22,23,0,14,4,5,7]},{"path":"tests/transformers/models/test_speech_seq2seq_models.py","lang":"python","classes":[],"functions":["check_seq2seq_pytorch_vs_kv_vs_ort_vs_ai100","load_seq2seq_model","run_seq2seq_ort","run_seq2seq_pytorch_hf","run_seq2seq_pytorch_with_kv","test_seq2seq_pytorch_vs_kv_vs_ort_vs_ai100","test_seq2seq_pytorch_vs_kv_vs_ort_vs_ai100_qnn"],"imports":[22,41,19,23,0,24,46,47,14,11,39,4,5,17,7,36]},{"path":"tests/finetune/reference_data.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"tests/finetune/constants.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"tests/finetune/test_finetune.py","lang":"python","classes":[],"functions":["assert_list_close","clean_up","download_alpaca","test_finetune"],"imports":[13,48,49,14,4,5,45,6,50,51,52]},{"path":"tests/base/test_pytorch_transforms.py","lang":"python","classes":["TestModel","TestTransform"],"functions":["test_module_mapping_transform","test_module_mutator_transform"],"imports":[53,5,17]},{"path":"tests/base/test_onnx_transforms.py","lang":"python","classes":[],"functions":["test_fp16clip_transform","test_fp16clip_transform_external","test_split_tensors_transform"],"imports":[54,14,11]},{"path":"tests/base/test_modeling_qeff.py","lang":"python","classes":[],"functions":["test_compiler_invalid_file","test_compiler_invalid_flag"],"imports":[55,11,5,56]},{"path":"tests/base/test_export_memory_offload.py","lang":"python","classes":["MockLangModel","MockModel","MockParam","MockSingleQPCModel","MockVisionModel"],"functions":["test_offload_weights_method","test_re_export_behavior_with_offloaded_weights","test_vlm_dual_qpc_memory_offload_behavior","test_vlm_single_qpc_memory_offload_behavior","tmp_cache"],"imports":[22,4,5,7]},{"path":"tests/cloud/test_infer.py","lang":"python","classes":[],"functions":["check_infer","test_infer","test_infer_fbs","test_infer_qnn","test_infer_qnn_fbs","test_infer_vlm"],"imports":[13,57,5]},{"path":"tests/cloud/test_export_compile_execute.py","lang":"python","classes":[],"functions":["check_export_compile_execute","test_export_compile_execute","test_export_compile_execute_fbs","test_export_compile_execute_qnn","test_export_compile_execute_qnn_fbs"],"imports":[13,58,59,4,5,60]},{"path":"QEfficient/__init__.py","lang":"python","classes":[],"functions":["check_qaic_sdk"],"imports":[61,62,40,21,63,64,19,1,65,4,32,66,67,68]},{"path":"QEfficient/utils/checkpoint_utils.py","lang":"python","classes":[],"functions":["load_checkpoint"],"imports":[69]},{"path":"QEfficient/utils/cache.py","lang":"python","classes":[],"functions":[],"imports":[4,20]},{"path":"QEfficient/utils/logging_utils.py","lang":"python","classes":["QEffFormatter"],"functions":["create_logger"],"imports":[70]},{"path":"QEfficient/utils/generate_qnn_network_specialization_config.py","lang":"python","classes":[],"functions":["generate_data_format_config","generate_qnn_specialization"],"imports":[3,11,36,60]},{"path":"QEfficient/utils/run_utils.py","lang":"python","classes":["ApiRunner","ApiRunnerInternVL","ApiRunnerVlm"],"functions":[],"imports":[21,71,14,11,39,4,17,7]},{"path":"QEfficient/utils/generate_inputs.py","lang":"python","classes":["InputHandler","InputHandlerInternVL","InputHandlerVLM"],"functions":[],"imports":[72,19,14,17,36]},{"path":"QEfficient/utils/spd_utils.py","lang":"python","classes":[],"functions":["get_speculative_config","get_speculative_weights"],"imports":[23,73,20,7]},{"path":"QEfficient/utils/model_registery.py","lang":"python","classes":[],"functions":[],"imports":[74,7]},{"path":"QEfficient/utils/device_utils.py","lang":"python","classes":[],"functions":["get_available_device_id","is_multi_qranium_setup_available","is_networks_loaded","is_qpc_size_gt_32gb"],"imports":[0,1,75,76,77]},{"path":"QEfficient/utils/__init__.py","lang":"python","classes":[],"functions":[],"imports":[41,23,8]},{"path":"QEfficient/utils/constants.py","lang":"python","classes":["Constants","QnnConstants"],"functions":["get_models_dir"],"imports":[37,4]},{"path":"QEfficient/utils/test_utils.py","lang":"python","classes":["InternProcessor","ModelConfig"],"functions":[],"imports":[17,78,79,80]},{"path":"QEfficient/utils/hash_utils.py","lang":"python","classes":[],"functions":["create_export_hash","hash_dict_params","json_serializable","to_hashable"],"imports":[0,81,3,36]},{"path":"QEfficient/utils/_utils.py","lang":"python","classes":["DownloadRetryLimitExceeded","IOInfo"],"functions":["check_and_assign_cache_dir","create_and_dump_qconfigs","create_json","create_model_params","custom_format_warning","dump_qconfig","execute_command","export_wrapper","filter_kwargs","generate_mdp_partition_config","get_num_layers_from_config","get_num_layers_vlm","get_onnx_dir_name","get_padding_shape_from_config","get_padding_shape_vlm","get_qaic_sdk_version","get_qpc_dir_path","get_sliding_window_layers","get_sliding_window_shapes","hf_download","load_hf_processor","load_hf_tokenizer","load_json","load_yaml","login_and_download_hf_lm","make_serializable","model_swap","onnx_exists","padding_check_and_fix","qpc_exists"],"imports":[82,0,8,1,34,37,73,83,3,4,20,45,84,77,17,7,36,85,60]},{"path":"QEfficient/peft/pytorch_transforms.py","lang":"python","classes":["PeftModelInputsTransform"],"functions":[],"imports":[53,86,15]},{"path":"QEfficient/peft/auto.py","lang":"python","classes":["QEffAutoPeftModelForCausalLM"],"functions":[],"imports":[55,54,53,35,18,10,87,27,19,23,8,81,70,14,15,17,7,88,36,68]},{"path":"QEfficient/peft/peft_model.py","lang":"python","classes":["QEffPeftModelForCausalLM"],"functions":[],"imports":[15]},{"path":"QEfficient/peft/__init__.py","lang":"python","classes":[],"functions":[],"imports":[89,86]},{"path":"QEfficient/peft/onnx_transforms.py","lang":"python","classes":["AdapterWeightsToInputsTransform"],"functions":[],"imports":[54,11,36]},{"path":"QEfficient/peft/lora/pytorch_transforms.py","lang":"python","classes":["LoraModelInputsTransform","TargetModulesTransform"],"functions":[],"imports":[53,90,91,92,93,17,36]},{"path":"QEfficient/peft/lora/auto.py","lang":"python","classes":["QEffAutoLoraModelForCausalLM"],"functions":[],"imports":[13,94,19,8,1,81,20,15,17,78,7,36]},{"path":"QEfficient/peft/lora/__init__.py","lang":"python","classes":[],"functions":[],"imports":[95]},{"path":"QEfficient/peft/lora/lora_model.py","lang":"python","classes":["QEffLoraModelLlamaForCausalLM","QEffLoraModelMistralForCausalLM"],"functions":[],"imports":[92,93,17,96,36]},{"path":"QEfficient/peft/lora/layers.py","lang":"python","classes":["LinearBase","LinearMultiLoRA"],"functions":[],"imports":[97,75,17,78,98,36]},{"path":"QEfficient/customop/ctx_scatter_gather_cb.py","lang":"python","classes":["CtxGatherFuncCB","CtxGatherFuncCB3D","CtxScatterFuncCB","CtxScatterFuncCB3D"],"functions":["CtxGatherCB","CtxGatherCB3D","CtxScatterCB","CtxScatterCB3D"],"imports":[19,99,17]},{"path":"QEfficient/customop/rms_norm.py","lang":"python","classes":["CustomRMSNormAIC","CustomRMSNormFunc","GemmaCustomRMSNormAIC"],"functions":["CustomRMSNorm"],"imports":[19,99,17]},{"path":"QEfficient/customop/ctx_scatter_gather.py","lang":"python","classes":["CtxGatherFunc","CtxGatherFunc3D","CtxScatterFunc","CtxScatterFunc3D"],"functions":["CtxGather","CtxGather3D","CtxScatter","CtxScatter3D"],"imports":[19,99,17]},{"path":"QEfficient/customop/matmulnbits.py","lang":"python","classes":["QuantLinearORT","QuantLinearTorchFunction"],"functions":["dequantize_blockwise_bits"],"imports":[75,17]},{"path":"QEfficient/customop/__init__.py","lang":"python","classes":[],"functions":[],"imports":[100,101,102]},{"path":"QEfficient/generation/text_generation_inference.py","lang":"python","classes":["CloudAI100ExecInfo","CloudAI100ExecInfoNew","PerfMetrics","QEffTextGenerationBase","TextGeneration"],"functions":["calculate_latency","cloud_ai_100_exec_kv","fix_prompt_to_lora_id_mapping","fix_prompts","get_compilation_dims","get_input_prompts","latency_stats_bertstyle","print_latency_stats_kv","read_prompts_txt_file","write_io_files"],"imports":[35,19,1,103,37,3,14,4,16,7,36]},{"path":"QEfficient/generation/cloud_infer.py","lang":"python","classes":["QAICInferenceSession"],"functions":[],"imports":[104,14,20,32,66,67,36,68]},{"path":"QEfficient/generation/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/post_processing.py","lang":"python","classes":[],"functions":["build_and_attach_mlp"],"imports":[31,105]},{"path":"QEfficient/transformers/transform.py","lang":"python","classes":[],"functions":["get_params_hash","replace_module_with_qeff_layers","transform","transform_lm"],"imports":[55,106,72,1,81,78,7]},{"path":"QEfficient/transformers/cache_utils.py","lang":"python","classes":["QEffDynamicCache","QEffEncoderDecoderCache","QEffHybridCache","QEffHybridChunkedCache"],"functions":[],"imports":[97,17,33,36]},{"path":"QEfficient/transformers/modeling_attn_mask_utils.py","lang":"python","classes":[],"functions":["_create_causal_mask"],"imports":[17,36]},{"path":"QEfficient/transformers/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/modeling_utils.py","lang":"python","classes":[],"functions":["_create_causal_mask","_prepare_aspect_ratio_attention_mask","_prepare_cross_attention_mask","build_model_class_mapping"],"imports":[97,0,103,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,17,78,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,36]},{"path":"QEfficient/transformers/spd/spd_transform_forward.py","lang":"python","classes":[],"functions":["filter_hidden_states","project_hidden_states","tlm_forward"],"imports":[17,98,33,96,36]},{"path":"QEfficient/transformers/spd/turbo.py","lang":"python","classes":["ResBlock"],"functions":["build_and_attach_turbo","post_process_turbo_state_dict"],"imports":[141,17]},{"path":"QEfficient/transformers/spd/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/embeddings/embedding_utils.py","lang":"python","classes":["PooledModel"],"functions":["average_pool","cls_pooling","max_pooling","mean_pooling","validate_user_pooling_function"],"imports":[83,17,78,36]},{"path":"QEfficient/transformers/embeddings/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/sampler/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/sampler/sampler.py","lang":"python","classes":["SamplerOutput"],"functions":["decode_path","prefill_path","sampler_forward"],"imports":[97,0,37,17,33,96,36]},{"path":"QEfficient/transformers/quantizers/quant_transforms.py","lang":"python","classes":["AwqToMatmulNbitsTransform","FP8DeQuantLinearToLinearTransform","GPTQToMatmulNbitsTransform"],"functions":[],"imports":[53,26,28,29,142,143,17]},{"path":"QEfficient/transformers/quantizers/awq.py","lang":"python","classes":["WQLinear_GEMM"],"functions":[],"imports":[143,17,78]},{"path":"QEfficient/transformers/quantizers/auto.py","lang":"python","classes":[],"functions":["replace_transformers_quantizers","undo_transformers_quantizers","with_replaced_quantizers"],"imports":[144,142,145,146,147,148,149,150]},{"path":"QEfficient/transformers/quantizers/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/quantizers/quantizer_utils.py","lang":"python","classes":["ScaledActivation"],"functions":["dequantize_gemm","dequantize_gptq","find_tied_parameters","get_keys_to_not_convert","repack_zeros","replace_linear_layer_with_target_layer","replace_quantization_scales","reverse_awq_order","unpack_weights","unpack_weights_and_zeros"],"imports":[34,17,151]},{"path":"QEfficient/transformers/quantizers/quantizer_awq.py","lang":"python","classes":["QEffAwqConfig","QEffAwqQuantizer"],"functions":[],"imports":[28,143,1,17,147,150]},{"path":"QEfficient/transformers/quantizers/gptq.py","lang":"python","classes":["QuantLinearGPTQ"],"functions":[],"imports":[143,75,17]},{"path":"QEfficient/transformers/quantizers/quantizer_compressed_tensors.py","lang":"python","classes":["FP8DeQuantLinear","FP8QuantizationScheme","QEffCompressedTensorsConfig","QEffCompressedTensorsFP8Quantizer","QEffExtendedQuantizationMethod","QEffFP8Config","QEffFP8Quantizer"],"functions":[],"imports":[143,1,37,152,17,148,150,36]},{"path":"QEfficient/transformers/quantizers/quantizer_gptq.py","lang":"python","classes":["QEffGPTQConfig","QEffGPTQQuantizer"],"functions":[],"imports":[29,143,1,17,153,150]},{"path":"QEfficient/transformers/models/pytorch_transforms.py","lang":"python","classes":["CustomOpsTransform","KVCacheExternalModuleMapperTransform","KVCacheTransform","PoolingTransform","SamplerTransform","SpDTransform","VlmKVOffloadTransform","VlmNoKVOffloadTransform"],"functions":[],"imports":[53,97,38,154,155,156,157,158,159,160,161,162,163,164,165,92,166,167,168,93,169,170,171,172,173,174,175,176,177,178,179,17,124,125,126,127,180,128,129,130,181,182,131,183,184,185,132,133,134,135,136,137,138,139,140,56,36,68]},{"path":"QEfficient/transformers/models/modeling_auto.py","lang":"python","classes":["MultimodalUtilityMixin","QEFFAutoModel","QEFFAutoModelForCausalLM","QEFFAutoModelForImageTextToText","QEFFAutoModelForSpeechSeq2Seq","QEFFTransformersBase","QEffCausalLMForTextImageToTextModel","QEffVisionEncoderForTextImageToTextModel","_QEFFAutoModelForImageTextToTextSingleQPC","_QEffAutoModelForImageTextToTextDualQPC"],"functions":[],"imports":[13,55,54,53,35,21,72,27,41,30,19,1,14,20,16,17,78,7,36,68]},{"path":"QEfficient/transformers/models/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py","lang":"python","classes":["QEffGPTBigCodeAttention","QEffGPTBigCodeBlock","QEffGPTBigCodeForCausalLM","QEffGPTBigCodeModel"],"functions":["masked_softmax","upcast_masked_softmax","upcast_softmax"],"imports":[106,186,17,187,33,96,129,36]},{"path":"QEfficient/transformers/models/gpt_bigcode/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/phi/modeling_phi.py","lang":"python","classes":["QEffPhiAttention","QEffPhiDecoderLayer","QEffPhiForCausalLM","QEffPhiModel"],"functions":["eager_attention_forward"],"imports":[106,186,0,17,33,96,136,36]},{"path":"QEfficient/transformers/models/phi/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/grok_1/modeling_grok1.py","lang":"python","classes":["QEFFGrok1CustomRMSNormAIC","QEffGrok1DecoderLayer","QEffGrok1Model","QEffGrok1ModelForCausalLM","QEffGrok1MoeBlock","QEffGrok1MultiHeadAttention"],"functions":[],"imports":[102,106,186,92,0,17,78,98,96,131,36]},{"path":"QEfficient/transformers/models/grok_1/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava/modeling_llava.py","lang":"python","classes":["QEFFLlavaDecoderWrapper","QEFFLlavaEncoderWrapper","QEffLlavaForConditionalGeneration"],"functions":[],"imports":[23,1,17,78,187,184]},{"path":"QEfficient/transformers/models/mistral/modeling_mistral.py","lang":"python","classes":["QEffMistralAttention","QEffMistralDecoderLayer","QEffMistralForCausalLM","QEffMistralModel","QEffMistralRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,187,33,96,132,36]},{"path":"QEfficient/transformers/models/mistral/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma3/modeling_gemma3.py","lang":"python","classes":["GemmaRMSNormFunc","QEffGemma3Attention","QEffGemma3CustomRMSNormAIC","QEffGemma3DecoderLayer","QEffGemma3DecoderWrapper","QEffGemma3EncoderWrapper","QEffGemma3ForCausalLMModel","QEffGemma3ForConditionalGeneration","QEffGemma3RotaryEmbedding","QEffGemma3TextModel"],"functions":["_is_local","eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[102,106,186,19,23,0,34,17,33,96,180,36]},{"path":"QEfficient/transformers/models/gemma3/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/mixtral_moe/modeling_mixtral.py","lang":"python","classes":["QEffMixtralAttention","QEffMixtralForCausalLM","QEffMixtralModel","QEffMixtralRotaryEmbedding","QEffMixtralSparseMoeBlock","QeffMixtralDecoderLayer"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,98,33,96,133,36]},{"path":"QEfficient/transformers/models/mixtral_moe/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/qwen2/modeling_qwen2.py","lang":"python","classes":["QEffQwen2Attention","QEffQwen2DecoderLayer","QEffQwen2ForCausalLM","QEffQwen2Model","QEffQwen2RotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,187,33,96,138,36]},{"path":"QEfficient/transformers/models/qwen2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/mpt/modeling_mpt.py","lang":"python","classes":["QEFfMptModel","QEffMptAttention","QEffMptBlock","QEffMptForCausalLM"],"functions":[],"imports":[106,186,0,17,187,188,96,135,36]},{"path":"QEfficient/transformers/models/mpt/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/falcon/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/falcon/modeling_falcon.py","lang":"python","classes":["QEffFalconAttention","QEffFalconDecoderLayer","QEffFalconForCausalLM","QEffFalconModel","QEffFalconRotaryEmbedding"],"functions":["qeff_apply_rotary_pos_emb"],"imports":[106,186,0,75,17,78,187,33,96,125,36]},{"path":"QEfficient/transformers/models/llama_swiftkv/modeling_llama_swiftkv.py","lang":"python","classes":["QEffLlamaSwiftKVAttention","QEffLlamaSwiftKVConfig","QEffLlamaSwiftKVDecoderLayer","QEffLlamaSwiftKVForCausalLM","QEffLlamaSwiftKVModel"],"functions":[],"imports":[106,186,92,0,75,17,7,33,188,96,189,131,36]},{"path":"QEfficient/transformers/models/llama_swiftkv/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/granite/modeling_granite.py","lang":"python","classes":["QEffGraniteAttention","QEffGraniteForCausalLM","QEffGraniteModel","QEffGraniteRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,181,36]},{"path":"QEfficient/transformers/models/granite/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/phi3/modeling_phi3.py","lang":"python","classes":["QEffPhi3Attention","QEffPhi3DecoderLayer","QEffPhi3ForCausalLM","QEffPhi3Model","QEffPhi3RotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,187,33,96,137,36]},{"path":"QEfficient/transformers/models/phi3/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/mllama/modeling_mllama.py","lang":"python","classes":["QEffMllamaCrossAttentionDecoderLayer","QEffMllamaForCausalLM","QEffMllamaForConditionalGeneration","QEffMllamaRotaryEmbedding","QEffMllamaSelfAttentionDecoderLayer","QEffMllamaTextCrossAttentionSingleQPC","QEffMllamaTextCrossAttentionTwoQPC","QEffMllamaTextModel","QEffMllamaTextSelfAttention","QEffMllamaVisionEncoder","QEffMllamaVisionModel"],"functions":["qeff_apply_rotary_pos_emb"],"imports":[106,72,19,23,0,75,17,98,33,96,134,36]},{"path":"QEfficient/transformers/models/mllama/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/codegen/modeling_codegen.py","lang":"python","classes":["QEffCodeGenAttention","QEffCodeGenForCausalLM","QEffCodeGenModel","QeffCodeGenBlock"],"functions":[],"imports":[106,186,0,17,33,96,124,36]},{"path":"QEfficient/transformers/models/codegen/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava_next/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava_next/modeling_llava_next.py","lang":"python","classes":["QEffLlavaNextDecoderWrapper","QEffLlavaNextEncoderWrapper","QEffLlavaNextForConditionalGeneration"],"functions":[],"imports":[19,23,1,14,17,78,185]},{"path":"QEfficient/transformers/models/granitemoe/modeling_granitemoe.py","lang":"python","classes":["QEffGraniteMoeAttention","QEffGraniteMoeForCausalLM","QEffGraniteMoeMoE","QEffGraniteMoeModel","QEffGraniteMoeParallelExperts","QEffGraniteMoeRotaryEmbedding","QEffGraniteMoeTopKGating"],"functions":["qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,98,33,188,96,182,36]},{"path":"QEfficient/transformers/models/granitemoe/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma2/modeling_gemma2.py","lang":"python","classes":["QEffGemma2Attention","QEffGemma2DecoderLayer","QEffGemma2ForCausalLM","QEffGemma2Model","QEffGemma2RotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,190,96,127,36]},{"path":"QEfficient/transformers/models/gemma2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma/modeling_gemma.py","lang":"python","classes":["QEffGemmaAttention","QEffGemmaDecoderLayer","QEffGemmaForCausalLM","QEffGemmaModel","QEffGemmaRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,126,36]},{"path":"QEfficient/transformers/models/gptj/modeling_gptj.py","lang":"python","classes":["QEffGPTJAttention","QEffGPTJBlock","QEffGPTJForCausalLM","QEffGPTJModel"],"functions":["apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,130,191,36]},{"path":"QEfficient/transformers/models/gptj/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/starcoder2/modeling_starcoder2.py","lang":"python","classes":["QEFFStarcoder2DecoderLayer","QEffStarcoder2Attention","QEffStarcoder2ForCausalLM","QEffStarcoder2Model"],"functions":["eager_attention_forward"],"imports":[106,186,0,17,33,96,139,36]},{"path":"QEfficient/transformers/models/starcoder2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/internvl/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/internvl/modeling_internvl.py","lang":"python","classes":["QEffInternDecoderWrapper","QEffInternEncoderWrapper","QEffInternVLModel","QEffInternVisionEmbeddings"],"functions":[],"imports":[19,23,1,17,78,98]},{"path":"QEfficient/transformers/models/whisper/modeling_whisper.py","lang":"python","classes":["QEffWhisperAttention","QEffWhisperDecoder","QEffWhisperDecoderLayer","QEffWhisperEncoder","QEffWhisperForConditionalGeneration","QEffWhisperModel","QEffWhisperPositionalEmbedding"],"functions":[],"imports":[106,186,23,0,17,33,96,140,36]},{"path":"QEfficient/transformers/models/whisper/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llama4/modeling_llama4.py","lang":"python","classes":["QEffLlama4DecoderWrapper","QEffLlama4EncoderWrapper","QEffLlama4ForCausalLM","QEffLlama4ForConditionalGeneration","QEffLlama4TextAttention","QEffLlama4TextDecoderLayer","QEffLlama4TextExperts","QEffLlama4TextModel","QEffLlama4TextMoe","QEffLlama4TextRotaryEmbedding","QEffLlama4VisionAttention","QEffLlama4VisionModel","QEffLlama4VisionRotaryEmbedding"],"functions":["complex_mul_onnx_safe","eager_attention_forward","eager_attention_forward_vision","qeff_apply_rotary_emb","qeff_vision_apply_rotary_emb"],"imports":[106,186,19,23,0,75,17,33,96,192,183,36]},{"path":"QEfficient/transformers/models/llama4/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gpt2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gpt2/modeling_gpt2.py","lang":"python","classes":["QEffGPT2Attention","QEffGPT2Block","QEffGPT2LMHeadModel","QEffGPT2Model"],"functions":["eager_attention_forward"],"imports":[106,186,0,17,96,128,36]},{"path":"QEfficient/transformers/models/llama/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llama/modeling_llama.py","lang":"python","classes":["QEffLlamaAttention","QEffLlamaDecoderLayer","QEffLlamaForCausalLM","QEffLlamaModel","QEffLlamaRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,131,36]},{"path":"QEfficient/compile/qnn_compiler.py","lang":"python","classes":["QNN"],"functions":["compile"],"imports":[23,0,193,8,1,81,3,4,6,36]},{"path":"QEfficient/compile/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/compile/qnn_config.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/compile/compile_helper.py","lang":"python","classes":[],"functions":["compile","compile_kv_model_on_cloud_ai_100","create_and_dump_specializations"],"imports":[194,19,23,1,3,4,6,77,36,68]},{"path":"QEfficient/finetune/eval.py","lang":"python","classes":[],"functions":["main"],"imports":[195,196,197,70,14,4,15,9,17,198,7,199,200,201,68]},{"path":"QEfficient/finetune/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/data/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/data/sampler.py","lang":"python","classes":["DistributedLengthBasedBatchSampler","LengthBasedBatchSampler"],"functions":[],"imports":[202,9,17]},{"path":"QEfficient/finetune/utils/helper.py","lang":"python","classes":["Batching_Strategy","Device","Peft_Method","Task_Mode"],"functions":["enum_names","get_autocast_ctx","get_grad_scaler","get_op_verifier_ctx","get_rank","get_world_size","init_qaic_profiling","is_rank_zero","save_to_json","stop_qaic_profiling"],"imports":[203,152,3,4,17,204,205,206,207,36]},{"path":"QEfficient/finetune/utils/logging_utils.py","lang":"python","classes":["FTLogger"],"functions":[],"imports":[49,208,70,4]},{"path":"QEfficient/finetune/utils/dataset_utils.py","lang":"python","classes":[],"functions":["get_custom_data_collator","get_dataloader","get_dataloader_kwargs","get_longest_seq_length","get_preprocessed_dataset","padding_dataset"],"imports":[209,210,49,196,46,70,17,211,212,36]},{"path":"QEfficient/finetune/utils/parser.py","lang":"python","classes":[],"functions":["get_finetune_parser","str2bool"],"imports":[210,49,213,70]},{"path":"QEfficient/finetune/utils/plot_metrics.py","lang":"python","classes":[],"functions":["plot_metric","plot_metrics","plot_metrics_by_step","plot_single_metric_by_step"],"imports":[196,213,3,214,4]},{"path":"QEfficient/finetune/utils/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/utils/device_map.py","lang":"python","classes":[],"functions":["custom_device_map","get_device_map"],"imports":[49,23,14,17,7]},{"path":"QEfficient/finetune/utils/train_utils.py","lang":"python","classes":[],"functions":["evaluation","print_model_size","print_trainable_parameters","train"],"imports":[195,49,196,208,215,70,4,16,17,211,216,198,217,218]},{"path":"QEfficient/finetune/utils/config_utils.py","lang":"python","classes":[],"functions":["generate_dataset_config","generate_peft_config","load_config_file","update_config","validate_config"],"imports":[219,220,195,210,49,196,103,37,83,3,4,15,36,60]},{"path":"QEfficient/finetune/configs/sample_peft_config.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/configs/dataset_config.py","lang":"python","classes":["alpaca_dataset","custom_dataset","grammar_dataset","gsm8k_dataset","imdb_dataset"],"functions":[],"imports":[37]},{"path":"QEfficient/finetune/configs/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/configs/peft_config.py","lang":"python","classes":["LoraConfig"],"functions":[],"imports":[37,36]},{"path":"QEfficient/finetune/configs/training.py","lang":"python","classes":["TrainConfig"],"functions":[],"imports":[49,37,70]},{"path":"QEfficient/finetune/dataset/dataset_config.py","lang":"python","classes":[],"functions":[],"imports":[221,222,223,224,225]},{"path":"QEfficient/finetune/dataset/alpaca_dataset.py","lang":"python","classes":["InstructionDataset"],"functions":[],"imports":[196,34,3,17,52]},{"path":"QEfficient/finetune/dataset/gsm8k_dataset.py","lang":"python","classes":[],"functions":["get_gsm8k_dataset","pad_to_max_length","tokenize_and_mask"],"imports":[46,36]},{"path":"QEfficient/finetune/dataset/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/dataset/imdb_dataset.py","lang":"python","classes":[],"functions":["get_preprocessed_imdb"],"imports":[46,202]},{"path":"QEfficient/finetune/dataset/custom_dataset.py","lang":"python","classes":[],"functions":["get_custom_dataset","get_data_collator","load_module_from_py_file"],"imports":[196,47,70,20]},{"path":"QEfficient/finetune/dataset/grammar_dataset.py","lang":"python","classes":["grammar"],"functions":["get_dataset"],"imports":[196,46,20,52]},{"path":"QEfficient/finetune/dataset/custom_dataset/sample_dataset_preproc.py","lang":"python","classes":[],"functions":["get_data_collator","get_preprocessed_disc"],"imports":[46,212]},{"path":"QEfficient/finetune/dataset/custom_dataset/sample_dataset_config.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/exporter/export_utils.py","lang":"python","classes":[],"functions":["export_onnx","fix_onnx_fp16","generate_input_files","remove_temp_file","run_model_on_ort","save_onnx"],"imports":[54,70,14,11,39,4,6,67,17,36]},{"path":"QEfficient/exporter/export_hf_to_cloud_ai_100.py","lang":"python","classes":[],"functions":["convert_to_cloud_bertstyle","convert_to_cloud_kvstyle","export_bertstyle_model_to_onnx","export_kvstyle_transformed_model_to_onnx","export_lm_model_for_cloud","qualcomm_efficient_converter"],"imports":[226,55,227,22,19,0,71,1,4,6,17,7,36,68]},{"path":"QEfficient/exporter/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/base/pytorch_transforms.py","lang":"python","classes":["ExternalModuleMapperTransform","ModuleMappingTransform","ModuleMutatorTransform","PytorchTransform","SplitGateUpWeightsTransform"],"functions":[],"imports":[1,17,56,36]},{"path":"QEfficient/base/modeling_qeff.py","lang":"python","classes":["QEFFBaseModel"],"functions":[],"imports":[54,53,194,35,19,228,229,83,70,11,20,6,77,17,36,68]},{"path":"QEfficient/base/__init__.py","lang":"python","classes":[],"functions":[],"imports":[226,22]},{"path":"QEfficient/base/common.py","lang":"python","classes":["QEFFCommonLoader"],"functions":[],"imports":[55,72,19,4,7,36]},{"path":"QEfficient/base/onnx_transforms.py","lang":"python","classes":["FP16ClipTransform","OnnxTransform","SplitTensorsTransform"],"functions":[],"imports":[14,11,36]},{"path":"QEfficient/cloud/execute.py","lang":"python","classes":[],"functions":["main"],"imports":[21,19,213,36]},{"path":"QEfficient/cloud/infer.py","lang":"python","classes":[],"functions":["execute_vlm_model","main"],"imports":[43,226,19,1,213,70,45,67,7,123,36]},{"path":"QEfficient/cloud/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/cloud/compile.py","lang":"python","classes":[],"functions":[],"imports":[13,213]},{"path":"QEfficient/cloud/finetune.py","lang":"python","classes":[],"functions":["apply_peft","load_model_and_tokenizer","main","setup_dataloaders","setup_distributed_training","setup_seeds"],"imports":[195,230,231,232,49,196,233,234,23,70,14,15,9,17,211,78,51,235,52,198,7,36,68]},{"path":"QEfficient/cloud/export.py","lang":"python","classes":[],"functions":["get_onnx_model_path","main"],"imports":[226,19,1,213,4,36]},{"path":"examples/basic_gguf_models.py","lang":"python","classes":[],"functions":[],"imports":[13,7]},{"path":"examples/draft_spd_inference.py","lang":"python","classes":["SpDCloudAI100ExecInfo","SpDPerfMetrics"],"functions":["arg_parse","comma_separated_ints","draft_spec_decode_inference","get_padded_input_len","main","optional_int","run_prefill_on_draft_and_target","split_dlm_bonus_token_inputs"],"imports":[13,35,0,213,37,14,16,7,36]},{"path":"examples/pld_spd_inference.py","lang":"python","classes":["SpDCloudAI100ExecInfo","SpDPerfMetrics"],"functions":["arg_parse","comma_separated_ints","find_candidate_pred_tokens","get_padded_input_len","main","pld_spec_decode_inference","run_prefill_on_draft_and_target"],"imports":[13,35,213,37,14,16,7,36]},{"path":"examples/llama4_multi_image_example.py","lang":"python","classes":[],"functions":[],"imports":[13,17,7]},{"path":"examples/image_text_to_text_inference.py","lang":"python","classes":[],"functions":["run_model"],"imports":[43,13,45,7]},{"path":"examples/peft_models.py","lang":"python","classes":[],"functions":[],"imports":[13,7]},{"path":"examples/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"examples/prompts.txt","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/lora_models.py","lang":"python","classes":[],"functions":[],"imports":[13,19]},{"path":"examples/embedding_model.py","lang":"python","classes":[],"functions":["max_pooling"],"imports":[13,17,7]},{"path":"examples/multiprojs_spd_inference.py","lang":"python","classes":["CloudAI100ExecInfo","SpDPerfMetrics"],"functions":["arg_parse","comma_separated_ints","get_padded_input_len","get_session","main","multiprojs_spec_decode_inference","optional_int","run_prefill","split_dlm_bonus_token_inputs"],"imports":[13,35,0,213,37,14,16,7,36]},{"path":"examples/llama4_example.py","lang":"python","classes":[],"functions":[],"imports":[13,17,7]},{"path":"examples/intern_example/internvl_inference.py","lang":"python","classes":["InternProcessor"],"functions":["get_prompt","run_intern_on_aic"],"imports":[43,13,1,44,45,17,78,79,80,7,36]},{"path":"examples/intern_example/readme.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/speech_to_text/README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/speech_to_text/run_whisper_speech_to_text.py","lang":"python","classes":[],"functions":[],"imports":[13,46,7]},{"path":"examples/cpp_execution/README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/cpp_execution/InferenceSetIOBuffer.cpp","lang":"cpp","classes":["QBufferWrapper"],"functions":["QBufferWrapper","func","generatePrompt","get_logits_from_output_buffers","if","populateBuffer","populateBuffersWithInputs"],"imports":[]},{"path":"examples/cpp_execution/text_inference_using_cpp.py","lang":"python","classes":[],"functions":["cloud_ai_100_exec_kv_cpp","main","tokenize_decode_output","tokenize_for_prefill","tokenize_for_prefill_with_padded_len"],"imports":[236,13,59,21,19,1,213,70,4,20,67,7,36]},{"path":"examples/cpp_execution/CMakeLists.txt","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/granite_example/granite_vision_inference.py","lang":"python","classes":[],"functions":["run_model"],"imports":[43,13,45,7]},{"path":"examples/granite_example/readme.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/gemma3_example/fp32_nodes_gemma3_4b_text.yaml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/gemma3_example/gemma3_mm.py","lang":"python","classes":[],"functions":[],"imports":[13,17,7]},{"path":"examples/gemma3_example/fp32_mm.yaml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/gemma3_example/fp32_nodes_gemma3_27b_text.yaml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/gemma3_example/fp32_nodes_gemma3_27b_image.yaml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"examples/gemma3_example/fp32_nodes_gemma3_4b_image.yaml","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"notebooks/QEfficientGPT2.ipynb","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"notebooks/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"notebooks/QEfficientMPT.ipynb","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/requirements.txt","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/index.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/conf.py","lang":"python","classes":[],"functions":["setup"],"imports":[4,67]},{"path":"docs/_static/my_theme.css","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/upgrade.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/reference.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/introduction.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/blogs.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/python_api.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/cli_api.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/validate.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/installation.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/quick_start.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/release_docs.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/finetune.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/image/Cloud_AI_100.png","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/source/image/kv_cache_cloudai100.png","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/_templates/versions.html","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"docs/image/Cloud_AI_100.png","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"scripts/Jenkinsfile","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"scripts/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"scripts/specializations.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"scripts/finetune/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"scripts/finetune/run_ft_model.py","lang":"python","classes":[],"functions":[],"imports":[195,196,70,4,15,17,198,7,68]},{"path":"scripts/perplexity_computation/README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"scripts/perplexity_computation/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"scripts/perplexity_computation/calculate_perplexity.py","lang":"python","classes":["InferenceSession","ONNXInferenceSession","PytorchInferenceSession","QPCInferenceSession","WikiTextDataLoader","WikiTextDataset"],"functions":["calculate_perplexity","generate_tokens","main","to_torch","torch_perplexity"],"imports":[35,23,213,46,70,14,39,16,17,52,218,7]},{"path":"scripts/replicate_kv_head/README.md","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"scripts/replicate_kv_head/replicate_kv_heads.py","lang":"python","classes":[],"functions":["duplicate_weights_for_linear_layer","replicate_kv_heads"],"imports":[13,41,28,29,142,23,213,17,7,36]},{"path":"scripts/replicate_kv_head/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]}]}