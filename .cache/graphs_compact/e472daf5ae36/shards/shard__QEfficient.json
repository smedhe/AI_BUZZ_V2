{"meta":{"source_url":"https://github.com/quic/efficient-transformers/tree/main","owner":"quic","repo":"efficient-transformers","branch":"main","subpath":"","created_at":"2025-09-11T07:35:47Z","graph_id":"e472daf5ae36","totals":{"files":255,"classes":277,"functions":385,"imports":1146},"shard":"QEfficient"},"dicts":{"imports":["QEfficient.utils.constants","QEfficient.utils.logging_utils","QEfficient.utils.test_utils","json","os","pytest","shutil","transformers","QEfficient.utils.hash_utils","random","QEfficient.peft.onnx_transforms","onnx","textwrap","QEfficient","numpy","peft","time","torch","QEfficient.peft.lora","QEfficient.utils","pathlib","QEfficient.generation.text_generation_inference","QEfficient.transformers.models.modeling_auto","QEfficient.utils._utils","QEfficient.utils.device_utils","vllm","QEfficient.customop.matmulnbits","QEfficient.transformers.models.pytorch_transforms","QEfficient.transformers.quantizers.awq","QEfficient.transformers.quantizers.gptq","QEfficient.transformers.quantizers.quant_transforms","QEfficient.transformers.spd.turbo","platform","transformers.cache_utils","copy","QEfficient.generation.cloud_infer","typing","dataclasses","QEfficient.transformers.embeddings.embedding_utils","onnxruntime","QEfficient.exporter.export_hf_to_cloud_ai_100","QEfficient.transformers.quantizers.auto","QEfficient.utils.run_utils","PIL","io","requests","datasets","importlib","QEfficient.cloud.finetune","QEfficient.finetune.utils.helper","tests.finetune","torch.optim","torch.utils.data","QEfficient.base.pytorch_transforms","QEfficient.base.onnx_transforms","QEfficient.base.modeling_qeff","types","QEfficient.cloud.infer","QEfficient.cloud.execute","QEfficient.cloud.export","yaml","QEfficient.base","QEfficient.compile.compile_helper","QEfficient.peft","QEfficient.transformers.transform","QEfficient.utils.model_registery","qaicrt","sys","warnings","safetensors.torch","logging","QEfficient.utils.generate_inputs","QEfficient.transformers.modeling_utils","huggingface_hub","QEfficient.transformers.models.llama_swiftkv.modeling_llama_swiftkv","math","re","subprocess","torch.nn","torchvision.transforms","torchvision.transforms.functional","hashlib","QEfficient.utils.cache","inspect","requests.exceptions","xml.etree.ElementTree","QEfficient.peft.peft_model","QEfficient.peft.pytorch_transforms","transformers.generation.streamers","QEfficient.peft.auto","QEfficient.peft.lora.layers","QEfficient.peft.lora.lora_model","QEfficient.transformers.models.llama.modeling_llama","QEfficient.transformers.models.mistral.modeling_mistral","QEfficient.peft.lora.pytorch_transforms","QEfficient.peft.lora.auto","transformers.modeling_outputs","QEfficient.customop","torch.nn.functional","onnxscript","QEfficient.customop.ctx_scatter_gather","QEfficient.customop.ctx_scatter_gather_cb","QEfficient.customop.rms_norm","collections","QAicApi_pb2","QEfficient.utils.spd_utils","QEfficient.transformers.cache_utils","models.codegen.modeling_codegen","models.falcon.modeling_falcon","models.gemma.modeling_gemma","models.gemma2.modeling_gemma2","models.gpt2.modeling_gpt2","models.gpt_bigcode.modeling_gpt_bigcode","models.gptj.modeling_gptj","models.llama.modeling_llama","models.mistral.modeling_mistral","models.mixtral_moe.modeling_mixtral","models.mpt.modeling_mpt","models.phi.modeling_phi","models.phi3.modeling_phi3","models.qwen2.modeling_qwen2","models.starcoder2.modeling_starcoder2","models.whisper.modeling_whisper","transformers.models.auto.modeling_auto","transformers.models.codegen.modeling_codegen","transformers.models.falcon.modeling_falcon","transformers.models.gemma.modeling_gemma","transformers.models.gemma2.modeling_gemma2","transformers.models.gpt2.modeling_gpt2","transformers.models.gpt_bigcode.modeling_gpt_bigcode","transformers.models.gptj.modeling_gptj","transformers.models.llama.modeling_llama","transformers.models.mistral.modeling_mistral","transformers.models.mixtral.modeling_mixtral","transformers.models.mllama.modeling_mllama","transformers.models.mpt.modeling_mpt","transformers.models.phi.modeling_phi","transformers.models.phi3.modeling_phi3","transformers.models.qwen2.modeling_qwen2","transformers.models.starcoder2.modeling_starcoder2","transformers.models.whisper.modeling_whisper","QEfficient.utils.checkpoint_utils","QEfficient.transformers.quantizers.quantizer_compressed_tensors","QEfficient.transformers.quantizers.quantizer_utils","QEfficient.transformers.quantizers.quantizer_awq","QEfficient.transformers.quantizers.quantizer_gptq","transformers.quantizers.auto","transformers.quantizers.quantizer_awq","transformers.quantizers.quantizer_compressed_tensors","transformers.quantizers.quantizer_gptq","transformers.utils.quantization_config","transformers.integrations.awq","enum","transformers.quantizers","QEfficient.transformers.models.codegen.modeling_codegen","QEfficient.transformers.models.falcon.modeling_falcon","QEfficient.transformers.models.gemma.modeling_gemma","QEfficient.transformers.models.gemma2.modeling_gemma2","QEfficient.transformers.models.gemma3.modeling_gemma3","QEfficient.transformers.models.gpt2.modeling_gpt2","QEfficient.transformers.models.gpt_bigcode.modeling_gpt_bigcode","QEfficient.transformers.models.gptj.modeling_gptj","QEfficient.transformers.models.granite.modeling_granite","QEfficient.transformers.models.granitemoe.modeling_granitemoe","QEfficient.transformers.models.grok_1.modeling_grok1","QEfficient.transformers.models.internvl.modeling_internvl","QEfficient.transformers.models.llama4.modeling_llama4","QEfficient.transformers.models.llava.modeling_llava","QEfficient.transformers.models.llava_next.modeling_llava_next","QEfficient.transformers.models.mixtral_moe.modeling_mixtral","QEfficient.transformers.models.mllama.modeling_mllama","QEfficient.transformers.models.mpt.modeling_mpt","QEfficient.transformers.models.phi.modeling_phi","QEfficient.transformers.models.phi3.modeling_phi3","QEfficient.transformers.models.qwen2.modeling_qwen2","QEfficient.transformers.models.starcoder2.modeling_starcoder2","QEfficient.transformers.models.whisper.modeling_whisper","QEfficient.transformers.post_processing","QEfficient.transformers.sampler.sampler","QEfficient.transformers.spd.spd_transform_forward","transformers.models.gemma3.modeling_gemma3","transformers.models.granite.modeling_granite","transformers.models.granitemoe.modeling_granitemoe","transformers.models.llama4.modeling_llama4","transformers.models.llava.modeling_llava","transformers.models.llava_next.modeling_llava_next","QEfficient.transformers.modeling_attn_mask_utils","torch.utils.checkpoint","transformers.modeling_attn_mask_utils","transformers.modeling_utils","transformers.generation","transformers.utils.import_utils","transformers.modeling_rope_utils","QEfficient.utils.generate_qnn_network_specialization_config","QEfficient.compile.qnn_compiler","QEfficient.finetune.configs.training","QEfficient.finetune.utils.logging_utils","fire","torch_qaic","utils.config_utils","utils.dataset_utils","utils.train_utils","itertools","contextlib","torch.amp","torch.qaic.amp","torch_qaic.debug","torch_qaic.profile","datetime","QEfficient.finetune.data.sampler","QEfficient.finetune.dataset.dataset_config","torch.distributed","transformers.data","argparse","matplotlib.pyplot","functools","torch.utils.tensorboard","torchmetrics","tqdm","QEfficient.finetune.configs.dataset_config","QEfficient.finetune.configs.peft_config","QEfficient.finetune.dataset.alpaca_dataset","QEfficient.finetune.dataset.custom_dataset","QEfficient.finetune.dataset.grammar_dataset","QEfficient.finetune.dataset.gsm8k_dataset","QEfficient.finetune.dataset.imdb_dataset","QEfficient.base.common","QEfficient.exporter.export_utils","abc","gc","QEfficient.finetune.utils.config_utils","QEfficient.finetune.utils.dataset_utils","QEfficient.finetune.utils.device_map","QEfficient.finetune.utils.parser","QEfficient.finetune.utils.train_utils","torch.optim.lr_scheduler","InferenceSetIOBuffer"]},"files":[{"path":"QEfficient/__init__.py","lang":"python","classes":[],"functions":["check_qaic_sdk"],"imports":[61,62,40,21,63,64,19,1,65,4,32,66,67,68]},{"path":"QEfficient/utils/checkpoint_utils.py","lang":"python","classes":[],"functions":["load_checkpoint"],"imports":[69]},{"path":"QEfficient/utils/cache.py","lang":"python","classes":[],"functions":[],"imports":[4,20]},{"path":"QEfficient/utils/logging_utils.py","lang":"python","classes":["QEffFormatter"],"functions":["create_logger"],"imports":[70]},{"path":"QEfficient/utils/generate_qnn_network_specialization_config.py","lang":"python","classes":[],"functions":["generate_data_format_config","generate_qnn_specialization"],"imports":[3,11,36,60]},{"path":"QEfficient/utils/run_utils.py","lang":"python","classes":["ApiRunner","ApiRunnerInternVL","ApiRunnerVlm"],"functions":[],"imports":[21,71,14,11,39,4,17,7]},{"path":"QEfficient/utils/generate_inputs.py","lang":"python","classes":["InputHandler","InputHandlerInternVL","InputHandlerVLM"],"functions":[],"imports":[72,19,14,17,36]},{"path":"QEfficient/utils/spd_utils.py","lang":"python","classes":[],"functions":["get_speculative_config","get_speculative_weights"],"imports":[23,73,20,7]},{"path":"QEfficient/utils/model_registery.py","lang":"python","classes":[],"functions":[],"imports":[74,7]},{"path":"QEfficient/utils/device_utils.py","lang":"python","classes":[],"functions":["get_available_device_id","is_multi_qranium_setup_available","is_networks_loaded","is_qpc_size_gt_32gb"],"imports":[0,1,75,76,77]},{"path":"QEfficient/utils/__init__.py","lang":"python","classes":[],"functions":[],"imports":[41,23,8]},{"path":"QEfficient/utils/constants.py","lang":"python","classes":["Constants","QnnConstants"],"functions":["get_models_dir"],"imports":[37,4]},{"path":"QEfficient/utils/test_utils.py","lang":"python","classes":["InternProcessor","ModelConfig"],"functions":[],"imports":[17,78,79,80]},{"path":"QEfficient/utils/hash_utils.py","lang":"python","classes":[],"functions":["create_export_hash","hash_dict_params","json_serializable","to_hashable"],"imports":[0,81,3,36]},{"path":"QEfficient/utils/_utils.py","lang":"python","classes":["DownloadRetryLimitExceeded","IOInfo"],"functions":["check_and_assign_cache_dir","create_and_dump_qconfigs","create_json","create_model_params","custom_format_warning","dump_qconfig","execute_command","export_wrapper","filter_kwargs","generate_mdp_partition_config","get_num_layers_from_config","get_num_layers_vlm","get_onnx_dir_name","get_padding_shape_from_config","get_padding_shape_vlm","get_qaic_sdk_version","get_qpc_dir_path","get_sliding_window_layers","get_sliding_window_shapes","hf_download","load_hf_processor","load_hf_tokenizer","load_json","load_yaml","login_and_download_hf_lm","make_serializable","model_swap","onnx_exists","padding_check_and_fix","qpc_exists"],"imports":[82,0,8,1,34,37,73,83,3,4,20,45,84,77,17,7,36,85,60]},{"path":"QEfficient/peft/pytorch_transforms.py","lang":"python","classes":["PeftModelInputsTransform"],"functions":[],"imports":[53,86,15]},{"path":"QEfficient/peft/auto.py","lang":"python","classes":["QEffAutoPeftModelForCausalLM"],"functions":[],"imports":[55,54,53,35,18,10,87,27,19,23,8,81,70,14,15,17,7,88,36,68]},{"path":"QEfficient/peft/peft_model.py","lang":"python","classes":["QEffPeftModelForCausalLM"],"functions":[],"imports":[15]},{"path":"QEfficient/peft/__init__.py","lang":"python","classes":[],"functions":[],"imports":[89,86]},{"path":"QEfficient/peft/onnx_transforms.py","lang":"python","classes":["AdapterWeightsToInputsTransform"],"functions":[],"imports":[54,11,36]},{"path":"QEfficient/peft/lora/pytorch_transforms.py","lang":"python","classes":["LoraModelInputsTransform","TargetModulesTransform"],"functions":[],"imports":[53,90,91,92,93,17,36]},{"path":"QEfficient/peft/lora/auto.py","lang":"python","classes":["QEffAutoLoraModelForCausalLM"],"functions":[],"imports":[13,94,19,8,1,81,20,15,17,78,7,36]},{"path":"QEfficient/peft/lora/__init__.py","lang":"python","classes":[],"functions":[],"imports":[95]},{"path":"QEfficient/peft/lora/lora_model.py","lang":"python","classes":["QEffLoraModelLlamaForCausalLM","QEffLoraModelMistralForCausalLM"],"functions":[],"imports":[92,93,17,96,36]},{"path":"QEfficient/peft/lora/layers.py","lang":"python","classes":["LinearBase","LinearMultiLoRA"],"functions":[],"imports":[97,75,17,78,98,36]},{"path":"QEfficient/customop/ctx_scatter_gather_cb.py","lang":"python","classes":["CtxGatherFuncCB","CtxGatherFuncCB3D","CtxScatterFuncCB","CtxScatterFuncCB3D"],"functions":["CtxGatherCB","CtxGatherCB3D","CtxScatterCB","CtxScatterCB3D"],"imports":[19,99,17]},{"path":"QEfficient/customop/rms_norm.py","lang":"python","classes":["CustomRMSNormAIC","CustomRMSNormFunc","GemmaCustomRMSNormAIC"],"functions":["CustomRMSNorm"],"imports":[19,99,17]},{"path":"QEfficient/customop/ctx_scatter_gather.py","lang":"python","classes":["CtxGatherFunc","CtxGatherFunc3D","CtxScatterFunc","CtxScatterFunc3D"],"functions":["CtxGather","CtxGather3D","CtxScatter","CtxScatter3D"],"imports":[19,99,17]},{"path":"QEfficient/customop/matmulnbits.py","lang":"python","classes":["QuantLinearORT","QuantLinearTorchFunction"],"functions":["dequantize_blockwise_bits"],"imports":[75,17]},{"path":"QEfficient/customop/__init__.py","lang":"python","classes":[],"functions":[],"imports":[100,101,102]},{"path":"QEfficient/generation/text_generation_inference.py","lang":"python","classes":["CloudAI100ExecInfo","CloudAI100ExecInfoNew","PerfMetrics","QEffTextGenerationBase","TextGeneration"],"functions":["calculate_latency","cloud_ai_100_exec_kv","fix_prompt_to_lora_id_mapping","fix_prompts","get_compilation_dims","get_input_prompts","latency_stats_bertstyle","print_latency_stats_kv","read_prompts_txt_file","write_io_files"],"imports":[35,19,1,103,37,3,14,4,16,7,36]},{"path":"QEfficient/generation/cloud_infer.py","lang":"python","classes":["QAICInferenceSession"],"functions":[],"imports":[104,14,20,32,66,67,36,68]},{"path":"QEfficient/generation/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/post_processing.py","lang":"python","classes":[],"functions":["build_and_attach_mlp"],"imports":[31,105]},{"path":"QEfficient/transformers/transform.py","lang":"python","classes":[],"functions":["get_params_hash","replace_module_with_qeff_layers","transform","transform_lm"],"imports":[55,106,72,1,81,78,7]},{"path":"QEfficient/transformers/cache_utils.py","lang":"python","classes":["QEffDynamicCache","QEffEncoderDecoderCache","QEffHybridCache","QEffHybridChunkedCache"],"functions":[],"imports":[97,17,33,36]},{"path":"QEfficient/transformers/modeling_attn_mask_utils.py","lang":"python","classes":[],"functions":["_create_causal_mask"],"imports":[17,36]},{"path":"QEfficient/transformers/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/modeling_utils.py","lang":"python","classes":[],"functions":["_create_causal_mask","_prepare_aspect_ratio_attention_mask","_prepare_cross_attention_mask","build_model_class_mapping"],"imports":[97,0,103,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,17,78,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,36]},{"path":"QEfficient/transformers/spd/spd_transform_forward.py","lang":"python","classes":[],"functions":["filter_hidden_states","project_hidden_states","tlm_forward"],"imports":[17,98,33,96,36]},{"path":"QEfficient/transformers/spd/turbo.py","lang":"python","classes":["ResBlock"],"functions":["build_and_attach_turbo","post_process_turbo_state_dict"],"imports":[141,17]},{"path":"QEfficient/transformers/spd/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/embeddings/embedding_utils.py","lang":"python","classes":["PooledModel"],"functions":["average_pool","cls_pooling","max_pooling","mean_pooling","validate_user_pooling_function"],"imports":[83,17,78,36]},{"path":"QEfficient/transformers/embeddings/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/sampler/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/sampler/sampler.py","lang":"python","classes":["SamplerOutput"],"functions":["decode_path","prefill_path","sampler_forward"],"imports":[97,0,37,17,33,96,36]},{"path":"QEfficient/transformers/quantizers/quant_transforms.py","lang":"python","classes":["AwqToMatmulNbitsTransform","FP8DeQuantLinearToLinearTransform","GPTQToMatmulNbitsTransform"],"functions":[],"imports":[53,26,28,29,142,143,17]},{"path":"QEfficient/transformers/quantizers/awq.py","lang":"python","classes":["WQLinear_GEMM"],"functions":[],"imports":[143,17,78]},{"path":"QEfficient/transformers/quantizers/auto.py","lang":"python","classes":[],"functions":["replace_transformers_quantizers","undo_transformers_quantizers","with_replaced_quantizers"],"imports":[144,142,145,146,147,148,149,150]},{"path":"QEfficient/transformers/quantizers/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/quantizers/quantizer_utils.py","lang":"python","classes":["ScaledActivation"],"functions":["dequantize_gemm","dequantize_gptq","find_tied_parameters","get_keys_to_not_convert","repack_zeros","replace_linear_layer_with_target_layer","replace_quantization_scales","reverse_awq_order","unpack_weights","unpack_weights_and_zeros"],"imports":[34,17,151]},{"path":"QEfficient/transformers/quantizers/quantizer_awq.py","lang":"python","classes":["QEffAwqConfig","QEffAwqQuantizer"],"functions":[],"imports":[28,143,1,17,147,150]},{"path":"QEfficient/transformers/quantizers/gptq.py","lang":"python","classes":["QuantLinearGPTQ"],"functions":[],"imports":[143,75,17]},{"path":"QEfficient/transformers/quantizers/quantizer_compressed_tensors.py","lang":"python","classes":["FP8DeQuantLinear","FP8QuantizationScheme","QEffCompressedTensorsConfig","QEffCompressedTensorsFP8Quantizer","QEffExtendedQuantizationMethod","QEffFP8Config","QEffFP8Quantizer"],"functions":[],"imports":[143,1,37,152,17,148,150,36]},{"path":"QEfficient/transformers/quantizers/quantizer_gptq.py","lang":"python","classes":["QEffGPTQConfig","QEffGPTQQuantizer"],"functions":[],"imports":[29,143,1,17,153,150]},{"path":"QEfficient/transformers/models/pytorch_transforms.py","lang":"python","classes":["CustomOpsTransform","KVCacheExternalModuleMapperTransform","KVCacheTransform","PoolingTransform","SamplerTransform","SpDTransform","VlmKVOffloadTransform","VlmNoKVOffloadTransform"],"functions":[],"imports":[53,97,38,154,155,156,157,158,159,160,161,162,163,164,165,92,166,167,168,93,169,170,171,172,173,174,175,176,177,178,179,17,124,125,126,127,180,128,129,130,181,182,131,183,184,185,132,133,134,135,136,137,138,139,140,56,36,68]},{"path":"QEfficient/transformers/models/modeling_auto.py","lang":"python","classes":["MultimodalUtilityMixin","QEFFAutoModel","QEFFAutoModelForCausalLM","QEFFAutoModelForImageTextToText","QEFFAutoModelForSpeechSeq2Seq","QEFFTransformersBase","QEffCausalLMForTextImageToTextModel","QEffVisionEncoderForTextImageToTextModel","_QEFFAutoModelForImageTextToTextSingleQPC","_QEffAutoModelForImageTextToTextDualQPC"],"functions":[],"imports":[13,55,54,53,35,21,72,27,41,30,19,1,14,20,16,17,78,7,36,68]},{"path":"QEfficient/transformers/models/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py","lang":"python","classes":["QEffGPTBigCodeAttention","QEffGPTBigCodeBlock","QEffGPTBigCodeForCausalLM","QEffGPTBigCodeModel"],"functions":["masked_softmax","upcast_masked_softmax","upcast_softmax"],"imports":[106,186,17,187,33,96,129,36]},{"path":"QEfficient/transformers/models/gpt_bigcode/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/phi/modeling_phi.py","lang":"python","classes":["QEffPhiAttention","QEffPhiDecoderLayer","QEffPhiForCausalLM","QEffPhiModel"],"functions":["eager_attention_forward"],"imports":[106,186,0,17,33,96,136,36]},{"path":"QEfficient/transformers/models/phi/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/grok_1/modeling_grok1.py","lang":"python","classes":["QEFFGrok1CustomRMSNormAIC","QEffGrok1DecoderLayer","QEffGrok1Model","QEffGrok1ModelForCausalLM","QEffGrok1MoeBlock","QEffGrok1MultiHeadAttention"],"functions":[],"imports":[102,106,186,92,0,17,78,98,96,131,36]},{"path":"QEfficient/transformers/models/grok_1/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava/modeling_llava.py","lang":"python","classes":["QEFFLlavaDecoderWrapper","QEFFLlavaEncoderWrapper","QEffLlavaForConditionalGeneration"],"functions":[],"imports":[23,1,17,78,187,184]},{"path":"QEfficient/transformers/models/mistral/modeling_mistral.py","lang":"python","classes":["QEffMistralAttention","QEffMistralDecoderLayer","QEffMistralForCausalLM","QEffMistralModel","QEffMistralRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,187,33,96,132,36]},{"path":"QEfficient/transformers/models/mistral/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma3/modeling_gemma3.py","lang":"python","classes":["GemmaRMSNormFunc","QEffGemma3Attention","QEffGemma3CustomRMSNormAIC","QEffGemma3DecoderLayer","QEffGemma3DecoderWrapper","QEffGemma3EncoderWrapper","QEffGemma3ForCausalLMModel","QEffGemma3ForConditionalGeneration","QEffGemma3RotaryEmbedding","QEffGemma3TextModel"],"functions":["_is_local","eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[102,106,186,19,23,0,34,17,33,96,180,36]},{"path":"QEfficient/transformers/models/gemma3/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/mixtral_moe/modeling_mixtral.py","lang":"python","classes":["QEffMixtralAttention","QEffMixtralForCausalLM","QEffMixtralModel","QEffMixtralRotaryEmbedding","QEffMixtralSparseMoeBlock","QeffMixtralDecoderLayer"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,98,33,96,133,36]},{"path":"QEfficient/transformers/models/mixtral_moe/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/qwen2/modeling_qwen2.py","lang":"python","classes":["QEffQwen2Attention","QEffQwen2DecoderLayer","QEffQwen2ForCausalLM","QEffQwen2Model","QEffQwen2RotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,187,33,96,138,36]},{"path":"QEfficient/transformers/models/qwen2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/mpt/modeling_mpt.py","lang":"python","classes":["QEFfMptModel","QEffMptAttention","QEffMptBlock","QEffMptForCausalLM"],"functions":[],"imports":[106,186,0,17,187,188,96,135,36]},{"path":"QEfficient/transformers/models/mpt/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/falcon/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/falcon/modeling_falcon.py","lang":"python","classes":["QEffFalconAttention","QEffFalconDecoderLayer","QEffFalconForCausalLM","QEffFalconModel","QEffFalconRotaryEmbedding"],"functions":["qeff_apply_rotary_pos_emb"],"imports":[106,186,0,75,17,78,187,33,96,125,36]},{"path":"QEfficient/transformers/models/llama_swiftkv/modeling_llama_swiftkv.py","lang":"python","classes":["QEffLlamaSwiftKVAttention","QEffLlamaSwiftKVConfig","QEffLlamaSwiftKVDecoderLayer","QEffLlamaSwiftKVForCausalLM","QEffLlamaSwiftKVModel"],"functions":[],"imports":[106,186,92,0,75,17,7,33,188,96,189,131,36]},{"path":"QEfficient/transformers/models/llama_swiftkv/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/granite/modeling_granite.py","lang":"python","classes":["QEffGraniteAttention","QEffGraniteForCausalLM","QEffGraniteModel","QEffGraniteRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,181,36]},{"path":"QEfficient/transformers/models/granite/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/phi3/modeling_phi3.py","lang":"python","classes":["QEffPhi3Attention","QEffPhi3DecoderLayer","QEffPhi3ForCausalLM","QEffPhi3Model","QEffPhi3RotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,187,33,96,137,36]},{"path":"QEfficient/transformers/models/phi3/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/mllama/modeling_mllama.py","lang":"python","classes":["QEffMllamaCrossAttentionDecoderLayer","QEffMllamaForCausalLM","QEffMllamaForConditionalGeneration","QEffMllamaRotaryEmbedding","QEffMllamaSelfAttentionDecoderLayer","QEffMllamaTextCrossAttentionSingleQPC","QEffMllamaTextCrossAttentionTwoQPC","QEffMllamaTextModel","QEffMllamaTextSelfAttention","QEffMllamaVisionEncoder","QEffMllamaVisionModel"],"functions":["qeff_apply_rotary_pos_emb"],"imports":[106,72,19,23,0,75,17,98,33,96,134,36]},{"path":"QEfficient/transformers/models/mllama/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/codegen/modeling_codegen.py","lang":"python","classes":["QEffCodeGenAttention","QEffCodeGenForCausalLM","QEffCodeGenModel","QeffCodeGenBlock"],"functions":[],"imports":[106,186,0,17,33,96,124,36]},{"path":"QEfficient/transformers/models/codegen/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava_next/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llava_next/modeling_llava_next.py","lang":"python","classes":["QEffLlavaNextDecoderWrapper","QEffLlavaNextEncoderWrapper","QEffLlavaNextForConditionalGeneration"],"functions":[],"imports":[19,23,1,14,17,78,185]},{"path":"QEfficient/transformers/models/granitemoe/modeling_granitemoe.py","lang":"python","classes":["QEffGraniteMoeAttention","QEffGraniteMoeForCausalLM","QEffGraniteMoeMoE","QEffGraniteMoeModel","QEffGraniteMoeParallelExperts","QEffGraniteMoeRotaryEmbedding","QEffGraniteMoeTopKGating"],"functions":["qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,98,33,188,96,182,36]},{"path":"QEfficient/transformers/models/granitemoe/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma2/modeling_gemma2.py","lang":"python","classes":["QEffGemma2Attention","QEffGemma2DecoderLayer","QEffGemma2ForCausalLM","QEffGemma2Model","QEffGemma2RotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,190,96,127,36]},{"path":"QEfficient/transformers/models/gemma2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gemma/modeling_gemma.py","lang":"python","classes":["QEffGemmaAttention","QEffGemmaDecoderLayer","QEffGemmaForCausalLM","QEffGemmaModel","QEffGemmaRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,126,36]},{"path":"QEfficient/transformers/models/gptj/modeling_gptj.py","lang":"python","classes":["QEffGPTJAttention","QEffGPTJBlock","QEffGPTJForCausalLM","QEffGPTJModel"],"functions":["apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,130,191,36]},{"path":"QEfficient/transformers/models/gptj/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/starcoder2/modeling_starcoder2.py","lang":"python","classes":["QEFFStarcoder2DecoderLayer","QEffStarcoder2Attention","QEffStarcoder2ForCausalLM","QEffStarcoder2Model"],"functions":["eager_attention_forward"],"imports":[106,186,0,17,33,96,139,36]},{"path":"QEfficient/transformers/models/starcoder2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/internvl/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/internvl/modeling_internvl.py","lang":"python","classes":["QEffInternDecoderWrapper","QEffInternEncoderWrapper","QEffInternVLModel","QEffInternVisionEmbeddings"],"functions":[],"imports":[19,23,1,17,78,98]},{"path":"QEfficient/transformers/models/whisper/modeling_whisper.py","lang":"python","classes":["QEffWhisperAttention","QEffWhisperDecoder","QEffWhisperDecoderLayer","QEffWhisperEncoder","QEffWhisperForConditionalGeneration","QEffWhisperModel","QEffWhisperPositionalEmbedding"],"functions":[],"imports":[106,186,23,0,17,33,96,140,36]},{"path":"QEfficient/transformers/models/whisper/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llama4/modeling_llama4.py","lang":"python","classes":["QEffLlama4DecoderWrapper","QEffLlama4EncoderWrapper","QEffLlama4ForCausalLM","QEffLlama4ForConditionalGeneration","QEffLlama4TextAttention","QEffLlama4TextDecoderLayer","QEffLlama4TextExperts","QEffLlama4TextModel","QEffLlama4TextMoe","QEffLlama4TextRotaryEmbedding","QEffLlama4VisionAttention","QEffLlama4VisionModel","QEffLlama4VisionRotaryEmbedding"],"functions":["complex_mul_onnx_safe","eager_attention_forward","eager_attention_forward_vision","qeff_apply_rotary_emb","qeff_vision_apply_rotary_emb"],"imports":[106,186,19,23,0,75,17,33,96,192,183,36]},{"path":"QEfficient/transformers/models/llama4/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gpt2/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/gpt2/modeling_gpt2.py","lang":"python","classes":["QEffGPT2Attention","QEffGPT2Block","QEffGPT2LMHeadModel","QEffGPT2Model"],"functions":["eager_attention_forward"],"imports":[106,186,0,17,96,128,36]},{"path":"QEfficient/transformers/models/llama/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/transformers/models/llama/modeling_llama.py","lang":"python","classes":["QEffLlamaAttention","QEffLlamaDecoderLayer","QEffLlamaForCausalLM","QEffLlamaModel","QEffLlamaRotaryEmbedding"],"functions":["eager_attention_forward","qeff_apply_rotary_pos_emb"],"imports":[106,186,0,17,33,96,131,36]},{"path":"QEfficient/compile/qnn_compiler.py","lang":"python","classes":["QNN"],"functions":["compile"],"imports":[23,0,193,8,1,81,3,4,6,36]},{"path":"QEfficient/compile/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/compile/qnn_config.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/compile/compile_helper.py","lang":"python","classes":[],"functions":["compile","compile_kv_model_on_cloud_ai_100","create_and_dump_specializations"],"imports":[194,19,23,1,3,4,6,77,36,68]},{"path":"QEfficient/finetune/eval.py","lang":"python","classes":[],"functions":["main"],"imports":[195,196,197,70,14,4,15,9,17,198,7,199,200,201,68]},{"path":"QEfficient/finetune/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/data/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/data/sampler.py","lang":"python","classes":["DistributedLengthBasedBatchSampler","LengthBasedBatchSampler"],"functions":[],"imports":[202,9,17]},{"path":"QEfficient/finetune/utils/helper.py","lang":"python","classes":["Batching_Strategy","Device","Peft_Method","Task_Mode"],"functions":["enum_names","get_autocast_ctx","get_grad_scaler","get_op_verifier_ctx","get_rank","get_world_size","init_qaic_profiling","is_rank_zero","save_to_json","stop_qaic_profiling"],"imports":[203,152,3,4,17,204,205,206,207,36]},{"path":"QEfficient/finetune/utils/logging_utils.py","lang":"python","classes":["FTLogger"],"functions":[],"imports":[49,208,70,4]},{"path":"QEfficient/finetune/utils/dataset_utils.py","lang":"python","classes":[],"functions":["get_custom_data_collator","get_dataloader","get_dataloader_kwargs","get_longest_seq_length","get_preprocessed_dataset","padding_dataset"],"imports":[209,210,49,196,46,70,17,211,212,36]},{"path":"QEfficient/finetune/utils/parser.py","lang":"python","classes":[],"functions":["get_finetune_parser","str2bool"],"imports":[210,49,213,70]},{"path":"QEfficient/finetune/utils/plot_metrics.py","lang":"python","classes":[],"functions":["plot_metric","plot_metrics","plot_metrics_by_step","plot_single_metric_by_step"],"imports":[196,213,3,214,4]},{"path":"QEfficient/finetune/utils/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/utils/device_map.py","lang":"python","classes":[],"functions":["custom_device_map","get_device_map"],"imports":[49,23,14,17,7]},{"path":"QEfficient/finetune/utils/train_utils.py","lang":"python","classes":[],"functions":["evaluation","print_model_size","print_trainable_parameters","train"],"imports":[195,49,196,208,215,70,4,16,17,211,216,198,217,218]},{"path":"QEfficient/finetune/utils/config_utils.py","lang":"python","classes":[],"functions":["generate_dataset_config","generate_peft_config","load_config_file","update_config","validate_config"],"imports":[219,220,195,210,49,196,103,37,83,3,4,15,36,60]},{"path":"QEfficient/finetune/configs/sample_peft_config.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/configs/dataset_config.py","lang":"python","classes":["alpaca_dataset","custom_dataset","grammar_dataset","gsm8k_dataset","imdb_dataset"],"functions":[],"imports":[37]},{"path":"QEfficient/finetune/configs/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/configs/peft_config.py","lang":"python","classes":["LoraConfig"],"functions":[],"imports":[37,36]},{"path":"QEfficient/finetune/configs/training.py","lang":"python","classes":["TrainConfig"],"functions":[],"imports":[49,37,70]},{"path":"QEfficient/finetune/dataset/dataset_config.py","lang":"python","classes":[],"functions":[],"imports":[221,222,223,224,225]},{"path":"QEfficient/finetune/dataset/alpaca_dataset.py","lang":"python","classes":["InstructionDataset"],"functions":[],"imports":[196,34,3,17,52]},{"path":"QEfficient/finetune/dataset/gsm8k_dataset.py","lang":"python","classes":[],"functions":["get_gsm8k_dataset","pad_to_max_length","tokenize_and_mask"],"imports":[46,36]},{"path":"QEfficient/finetune/dataset/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/finetune/dataset/imdb_dataset.py","lang":"python","classes":[],"functions":["get_preprocessed_imdb"],"imports":[46,202]},{"path":"QEfficient/finetune/dataset/custom_dataset.py","lang":"python","classes":[],"functions":["get_custom_dataset","get_data_collator","load_module_from_py_file"],"imports":[196,47,70,20]},{"path":"QEfficient/finetune/dataset/grammar_dataset.py","lang":"python","classes":["grammar"],"functions":["get_dataset"],"imports":[196,46,20,52]},{"path":"QEfficient/finetune/dataset/custom_dataset/sample_dataset_preproc.py","lang":"python","classes":[],"functions":["get_data_collator","get_preprocessed_disc"],"imports":[46,212]},{"path":"QEfficient/finetune/dataset/custom_dataset/sample_dataset_config.json","lang":"text","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/exporter/export_utils.py","lang":"python","classes":[],"functions":["export_onnx","fix_onnx_fp16","generate_input_files","remove_temp_file","run_model_on_ort","save_onnx"],"imports":[54,70,14,11,39,4,6,67,17,36]},{"path":"QEfficient/exporter/export_hf_to_cloud_ai_100.py","lang":"python","classes":[],"functions":["convert_to_cloud_bertstyle","convert_to_cloud_kvstyle","export_bertstyle_model_to_onnx","export_kvstyle_transformed_model_to_onnx","export_lm_model_for_cloud","qualcomm_efficient_converter"],"imports":[226,55,227,22,19,0,71,1,4,6,17,7,36,68]},{"path":"QEfficient/exporter/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/base/pytorch_transforms.py","lang":"python","classes":["ExternalModuleMapperTransform","ModuleMappingTransform","ModuleMutatorTransform","PytorchTransform","SplitGateUpWeightsTransform"],"functions":[],"imports":[1,17,56,36]},{"path":"QEfficient/base/modeling_qeff.py","lang":"python","classes":["QEFFBaseModel"],"functions":[],"imports":[54,53,194,35,19,228,229,83,70,11,20,6,77,17,36,68]},{"path":"QEfficient/base/__init__.py","lang":"python","classes":[],"functions":[],"imports":[226,22]},{"path":"QEfficient/base/common.py","lang":"python","classes":["QEFFCommonLoader"],"functions":[],"imports":[55,72,19,4,7,36]},{"path":"QEfficient/base/onnx_transforms.py","lang":"python","classes":["FP16ClipTransform","OnnxTransform","SplitTensorsTransform"],"functions":[],"imports":[14,11,36]},{"path":"QEfficient/cloud/execute.py","lang":"python","classes":[],"functions":["main"],"imports":[21,19,213,36]},{"path":"QEfficient/cloud/infer.py","lang":"python","classes":[],"functions":["execute_vlm_model","main"],"imports":[43,226,19,1,213,70,45,67,7,123,36]},{"path":"QEfficient/cloud/__init__.py","lang":"python","classes":[],"functions":[],"imports":[]},{"path":"QEfficient/cloud/compile.py","lang":"python","classes":[],"functions":[],"imports":[13,213]},{"path":"QEfficient/cloud/finetune.py","lang":"python","classes":[],"functions":["apply_peft","load_model_and_tokenizer","main","setup_dataloaders","setup_distributed_training","setup_seeds"],"imports":[195,230,231,232,49,196,233,234,23,70,14,15,9,17,211,78,51,235,52,198,7,36,68]},{"path":"QEfficient/cloud/export.py","lang":"python","classes":[],"functions":["get_onnx_model_path","main"],"imports":[226,19,1,213,4,36]}]}