# QNN Compilation
## Overview
QNN compilation is a feature in the Efficient Transformers Library that allows models to be compiled for efficient inference on QNN hardware. This feature is designed to optimize the performance of models on QNN devices, making it an essential component of the library.

## Key Components / Concepts
The QNN compilation process involves several key components and concepts:

*   **QNN Compiler**: The QNN compiler is a tool that takes an ONNX model as input and generates a QPC (Quantization Package) that can be executed on QNN hardware.
*   **ONNX Model**: The ONNX model is the input to the QNN compiler. It is a representation of the model in a format that can be understood by the QNN compiler.
*   **QPC**: The QPC is the output of the QNN compiler. It is a package that contains the compiled model and can be executed on QNN hardware.

## How it Works
The QNN compilation process works as follows:

1.  The user exports an ONNX model from a Hugging Face model.
2.  The user runs the QNN compiler on the exported ONNX model to generate a QPC.
3.  The QPC is then executed on QNN hardware to perform inference.

## Example(s)
To compile a model using the QNN compiler, you can use the following code:
```python
from QEfficient import QEFFAutoModel

model = QEFFAutoModel.from_pretrained("model_name")
model.compile(num_cores=16)
```
This code initializes a QEFFAutoModel object from a pre-trained model and compiles it using the QNN compiler with 16 cores.

## Diagram(s)
```mermaid
graph LR
    A[Export ONNX Model] --> B[QNN Compiler]
    B --> C[QPC Generation]
    C --> D[QPC Execution]
    D --> E[Inference on QNN Hardware]
```
Caption: QNN Compilation Flowchart

## References
*   [QEfficient/compile/qnn_compiler.py](QEfficient/compile/qnn_compiler.py)
*   [QEfficient/transformers/models/modeling_auto.py](QEfficient/transformers/models/modeling_auto.py)
*   [docs/source/finetune.md](docs/source/finetune.md)